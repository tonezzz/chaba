# pc1-stack environment template
# Copy to .env (kept out of git) and replace secrets marked __REPLACE_ME__.

PC1_WORKSPACE_HOST_DIR=C:/chaba

# 1mcp-agent
ONE_MCP_PORT=3051

# User system (Authentik / MinIO / Vault)
AUTHENTIK_SECRET_KEY=__REPLACE_ME__
AUTHENTIK_POSTGRES_PASSWORD=__REPLACE_ME__
MINIO_ROOT_PASSWORD=__REPLACE_ME__
VAULT_DEV_ROOT_TOKEN_ID=__REPLACE_ME__

# MinIO SSO via Authentik (OIDC)
MINIO_IDENTITY_OPENID_CONFIG_URL=
MINIO_IDENTITY_OPENID_CLIENT_ID=
MINIO_IDENTITY_OPENID_CLIENT_SECRET=
MINIO_IDENTITY_OPENID_DISPLAY_NAME=Authentik
MINIO_IDENTITY_OPENID_CLAIM_NAME=policy
MINIO_IDENTITY_OPENID_SCOPES=openid,profile,email
MINIO_IDENTITY_OPENID_REDIRECT_URI_DYNAMIC=on

# MCP QuickChart
MCP_QUICKCHART_BUILD_CONTEXT=../../mcp/mcp-quickchart
MCP_QUICKCHART_PORT=8251
QUICKCHART_BASE_URL=https://quickchart.io
QUICKCHART_API_BASE_URL=https://api.quickchart.io
QUICKCHART_TIMEOUT_SECONDS=30
QUICKCHART_MAX_OUTPUT_BYTES=20000000

MCP_AGENTS_BUILD_CONTEXT=../../mcp/mcp-agents
MCP_AGENTS_PORT=8046
AGENTS_API_BASE=http://host.docker.internal:3100/test/agents/api
AGENTS_DEFAULT_USER=default
AGENTS_DEFAULT_LIMIT=12
AGENTS_JSON_LIMIT=2mb
MCP_AGENTS_DATA_DIR=./data/mcp-agents

MCP_GLAMA_BUILD_CONTEXT=../../mcp/mcp-glama
MCP_GLAMA_PORT=7241
GLAMA_API_URL=
GLAMA_API_KEY=__REPLACE_ME__
GLAMA_MODEL=gpt-4o-mini
GLAMA_TEMPERATURE=0.2
GLAMA_MAX_TOKENS=900
GLAMA_TIMEOUT_SECONDS=30

MCP_GITHUB_MODELS_BUILD_CONTEXT=../../mcp/mcp-github-models
MCP_GITHUB_MODELS_PORT=7242
GITHUB_MODELS_API_URL=
GITHUB_MODELS_API_KEY=__REPLACE_ME__
GITHUB_MODELS_MODEL=gpt-4o-mini
GITHUB_MODELS_TEMPERATURE=0.2
GITHUB_MODELS_MAX_TOKENS=900
GITHUB_MODELS_TIMEOUT_SECONDS=30

# OpenAI-compatible gateway for OpenChat UI
MCP_OPENAI_GATEWAY_BUILD_CONTEXT=../../mcp/mcp-openai-gateway
MCP_OPENAI_GATEWAY_PORT=8181
OPENAI_GATEWAY_MODEL_ID=glama-default
OPENAI_GATEWAY_TIMEOUT_SECONDS=60
OPENAI_GATEWAY_DEBUG=0

# Optional: use an MCP LLM tool instead of direct GLAMA_API_URL.
# Useful for selecting between mcp-glama and mcp-github-models.
OPENAI_GATEWAY_PREFER_MCP_LLM=0
# If set, pins the exact MCP tool name used as the LLM backend.
# Example values depend on 1mcp tool naming; see 1mcp tools/list.
OPENAI_GATEWAY_LLM_TOOL=

MCP_TESTER_BUILD_CONTEXT=../../mcp/mcp-tester
MCP_TESTER_PORT=8335
MCP_TESTER_DATA_DIR=./data/mcp-tester
MCP_TESTER_SUITE_FILE=/app/tests.example.json
MCP_TESTER_SUITE_FILES=/app/tests.optional.json
MCP_TESTER_DEFAULT_TIMEOUT_MS=5000
MCP_TESTER_HISTORY_FILE=/data/run-history.ndjson
DEV_HOST_TEST_BASE=http://host.docker.internal:3100
A1_IDC1_BASE_URL=https://a1.idc1.surf-thailand.com
A1_IDC1_TEST_URL=https://a1.idc1.surf-thailand.com/test

MCP_DEVOPS_BUILD_CONTEXT=../../mcp/mcp-devops
MCP_DEVOPS_PORT=8325
DEV_HOST_BASE_URL=http://host.docker.internal:3100
DEV_HOST_PC2_BASE_URL=http://dev-host.pc2:3000
MCP_DEVOPS_JSON_LIMIT=2mb

MCP_PLAYWRIGHT_BUILD_CONTEXT=../../mcp/mcp-playwright
MCP_PLAYWRIGHT_PORT=8260
PLAYWRIGHT_BROWSER=chromium
PLAYWRIGHT_HEADLESS=true
PLAYWRIGHT_TIMEOUT_MS=15000
MCP_PLAYWRIGHT_SCENARIOS_DIR=./data/mcp-playwright/scenarios
MCP_PLAYWRIGHT_OUTPUT_DIR=./data/mcp-playwright/output

# RAG stack (Ollama embeddings + Qdrant + mcp-rag)
MCP_RAG_BUILD_CONTEXT=../../mcp/mcp-rag
MCP_RAG_PORT=8055

QDRANT_PORT=6333
QDRANT_URL=http://qdrant:6333
QDRANT_TEXT_COLLECTION=rag_text
QDRANT_IMAGE_COLLECTION=rag_image

# Host port is 11435 by default to avoid conflict with local Windows Ollama on 11434.
OLLAMA_PORT=11435
OLLAMA_URL=http://ollama:11434
OLLAMA_EMBED_MODEL=nomic-embed-text

CLIP_MODEL=clip-ViT-B-32

WEBTOPS_ROUTER_BUILD_CONTEXT=../../mcp/webtops-router
WEBTOPS_ROUTER_PORT=3001
WEBTOPS_ROUTER_ADMIN_TOKEN=__REPLACE_ME__
WEBTOPS_ROUTER_STATE_DIR=./data/webtops-router

MCP_WEBTOPS_BUILD_CONTEXT=../../mcp/mcp-webtops
MCP_WEBTOPS_PORT=8091
WEBTOPS_ADMIN_TOKEN=__REPLACE_ME__
WEBTOPS_PUBLIC_BASE_URL=http://host.docker.internal:3001/webtop/
WEBTOPS_BASE_PATH=/webtop/
WEBTOPS_BACKEND=docker
WEBTOPS_DOCKER_NETWORK=pc1-stack_pc1-stack-net
WEBTOPS_SESSION_INTERNAL_PORT=3000
WEBTOPS_SESSION_IMAGE=lscr.io/linuxserver/webtop:latest
WEBTOPS_SESSION_UPSTREAM_SCHEME=http
WEBTOPS_SESSION_MOUNT_PATH=/config
WEBTOPS_SESSION_TZ=Asia/Bangkok
WEBTOPS_SESSION_PUID=1000
WEBTOPS_SESSION_PGID=1000
WEBTOPS_SESSION_PASSWORD=

# Windsurf profile (runtime download pinned version into /config)
WEBTOPS_SESSION_IMAGE_WINDSURF=webtops-windsurf-runtime:stable
WEBTOPS_WINDSURF_VERSION=1.12.47
WEBTOPS_WINDSURF_INSTALL_MODE=deb_extract
WEBTOPS_WINDSURF_DEB_URL_TEMPLATE=https://windsurf-stable.codeiumdata.com/wVxQEIWkwPUEAGf3/apt/pool/main/w/windsurf/Windsurf-linux-x64-{version}.deb

# Windsurf shared cache (download once per host; reused across sessions)
WEBTOPS_WINDSURF_CACHE_VOLUME=webtops_windsurf_cache
WEBTOPS_WINDSURF_CACHE_MOUNT_PATH=/windsurf-cache

# Shared workspaces volume (mounted into every session)
WEBTOPS_WORKSPACES_VOLUME=webtops_workspaces
WEBTOPS_WORKSPACES_MOUNT_PATH=/workspaces

# Optional: auto clone/pull repo into the workspaces volume on session startup
WEBTOPS_WORKSPACES_REPO_URL=
WEBTOPS_WORKSPACES_REPO_BRANCH=
WEBTOPS_WORKSPACES_REPO_DIR=/workspaces/chaba

# Optional AppImage mode (if you prefer):
# WEBTOPS_WINDSURF_INSTALL_MODE=appimage
# WEBTOPS_WINDSURF_DOWNLOAD_URL_TEMPLATE=__PINNED_URL_WITH_{version}__
WEBTOPS_SNAPSHOT_HOST_DIR=./data/mcp-webtops/snapshots
WEBTOPS_STATE_HOST_DIR=./data/mcp-webtops/state

# Register providers reachable from pc1 (edit as needed)

# OpenChat UI (Next.js)
OPENCHAT_UI_BUILD_CONTEXT=../../sites/openchat-ui
OPENCHAT_UI_PORT=3170
OPENCHAT_OPENAI_API_HOST=http://mcp-openai-gateway:8181
OPENCHAT_OPENAI_API_KEY=sk-dummy
OPENCHAT_DEFAULT_MODEL=glama-default
