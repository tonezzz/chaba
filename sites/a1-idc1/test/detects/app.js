const LANGUAGE_OPTIONS = [
  { value: 'th', label: 'à¹„à¸—à¸¢ (TH)', description: 'à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™' },
  { value: 'en', label: 'English (EN)', description: 'Default' },
  { value: 'de', label: 'Deutsch (DE)', description: 'German' },
  { value: 'no', label: 'Norsk (NO)', description: 'Norwegian' },
  { value: 'sv', label: 'Svenska (SV)', description: 'Swedish' },
  { value: 'es', label: 'EspaÃ±ol (ES)', description: 'Spanish' },
  { value: 'ja', label: 'æ—¥æœ¬èªž (JA)', description: 'Japanese' },
  { value: 'zh', label: 'ä¸­æ–‡ (ZH)', description: 'Chinese' },
  { value: 'ko', label: 'í•œêµ­ì–´ (KO)', description: 'Korean' }
];

const DEFAULT_LANGUAGE = 'th';
const PREFERRED_VISION_MODEL = 'gpt-4.1-2025-04-14';

const SPEECH_LOCALE_MAP = {
  th: 'th-TH',
  en: 'en-US',
  de: 'de-DE',
  no: 'nb-NO',
  sv: 'sv-SE',
  es: 'es-ES',
  ja: 'ja-JP',
  zh: 'zh-CN',
  ko: 'ko-KR'
};

const MAX_SPEECH_CHARACTERS = 800;
const SUPPORTS_SPEECH_RECOGNITION =
  typeof window !== 'undefined' &&
  (window.SpeechRecognition || window.webkitSpeechRecognition || null);

const resolveSpeechLocale = (code) => {
  const raw = (code || DEFAULT_LANGUAGE || 'en').trim();
  if (!raw) {
    return 'en-US';
  }
  if (raw.includes('-')) {
    return raw;
  }
  return SPEECH_LOCALE_MAP[raw] || 'en-US';
};

const DETECTION_PROMPT_TEMPLATES = [
  {
    id: 'urban',
    labelKey: 'promptUrbanLabel',
    textKey: 'promptUrbanText',
    fallbackLabel: 'Street operations sweep',
    fallbackText:
      'Describe traffic flow, signage status, crowd behavior, and note outages or hazards along the street.'
  },
  {
    id: 'retail',
    labelKey: 'promptRetailLabel',
    textKey: 'promptRetailText',
    fallbackLabel: 'Retail fixture compliance',
    fallbackText:
      'Audit shelf facings, promotional displays, and staff/customer interactions that affect merchandising discipline.'
  },
  {
    id: 'safety',
    labelKey: 'promptSafetyLabel',
    textKey: 'promptSafetyText',
    fallbackLabel: 'Safety compliance sweep',
    fallbackText: 'Scan for PPE usage, blocked exits, spills, or anything that could violate safety protocols.'
  },
  {
    id: 'vehicle',
    labelKey: 'promptVehicleLabel',
    textKey: 'promptVehicleText',
    fallbackLabel: 'Vehicle damage survey',
    fallbackText:
      'Inspect exterior panels, glass, and lights; flag dents, scratches, rust, missing parts, and capture license info.'
  },
  {
    id: 'document',
    labelKey: 'promptDocumentLabel',
    textKey: 'promptDocumentText',
    fallbackLabel: 'Manual / SOP comprehension',
    fallbackText: 'Summarize the document purpose, key steps, warnings, and tools that are mentioned.'
  },
  {
    id: 'invoice',
    labelKey: 'promptInvoiceLabel',
    textKey: 'promptInvoiceText',
    fallbackLabel: 'Receipt & slip extraction',
    fallbackText:
      'Transcribe totals, taxes, store info, payment method, and any handwritten notes shown on the slip.'
  }
];

const CHAT_PRESET_TEMPLATES = [
  {
    id: 'summary',
    labelKey: 'chatPresetSummary',
    textKey: 'chatPresetSummaryText',
    fallbackLabel: 'Quick summary',
    fallbackText: 'Give me a 2 sentence summary of the detections.'
  },
  {
    id: 'anomalies',
    labelKey: 'chatPresetAnomalies',
    textKey: 'chatPresetAnomaliesText',
    fallbackLabel: 'Policy & safety issues',
    fallbackText: 'List any compliance or safety issues that showed up.'
  },
  {
    id: 'next',
    labelKey: 'chatPresetNextSteps',
    textKey: 'chatPresetNextStepsText',
    fallbackLabel: 'Actionable next steps',
    fallbackText: 'What are the top 3 actions we should take next based on this scene?'
  },
  {
    id: 'inventory',
    labelKey: 'chatPresetInventory',
    textKey: 'chatPresetInventoryText',
    fallbackLabel: 'Inventory counts',
    fallbackText: 'Report notable inventory levels or items that look empty or overstocked.'
  },
  {
    id: 'risks',
    labelKey: 'chatPresetRisks',
    textKey: 'chatPresetRisksText',
    fallbackLabel: 'Risk factors',
    fallbackText: 'Call out any potential risks or hazards in this scene and why they matter.'
  }
];

const UI_COPY = {
  default: {
    heroEyebrow: 'Surf Thailand â€¢ A1 Vision Utilities',
    heroTitle: 'Photo understanding sandbox',
    heroLede:
      'Drop in a still photo, choose one of the vision prompts, and weâ€™ll send it through our Glama vision endpoint to describe the scene and pinpoint notable objects.',
    langLabel: 'Language',
    uploadHeading: '1. Upload photo',
    uploadBody: 'Single still image, max 10â€¯MB. Works great with portrait or landscape shots.',
    dropTitle: 'Drag & drop photo',
    dropAlt: 'or',
    browseButton: 'browse files',
    cameraButton: 'take a photo',
    fileHintEmpty: 'No file selected yet.',
    promptHeading: '2. Pick a vision brief',
    promptBody: 'Tap a chip to autofill the prompt, or fine-tune in the text box.',
    promptUrbanLabel: 'Street operations sweep',
    promptUrbanText:
      'Describe traffic flow, signage status, crowd behavior, and note outages or hazards along the street.',
    promptRetailLabel: 'Retail fixture compliance',
    promptRetailText:
      'Audit shelf facings, promotional displays, and staff/customer interactions that affect merchandising discipline.',
    promptSafetyLabel: 'Safety compliance sweep',
    promptSafetyText: 'Scan for PPE usage, blocked exits, spills, or anything that could violate safety protocols.',
    promptVehicleLabel: 'Vehicle damage survey',
    promptVehicleText:
      'Inspect exterior panels, glass, and lights; flag dents, scratches, rust, missing parts, and capture license info.',
    promptDocumentLabel: 'Manual / SOP comprehension',
    promptDocumentText: 'Summarize the document purpose, key steps, warnings, and tools that are mentioned.',
    modelLabel: 'Vision model',
    modelTagLabel: 'LLM',
    latencyLabel: 'Latency',
    promptLabel: 'Custom instructions',
    promptPlaceholder: 'Explain what you want the model to focus onâ€¦',
    analyzeButtonIdle: 'Run describe + detect',
    analyzeButtonBusy: 'Analyzingâ€¦',
    statusWaiting: 'Waiting for your photoâ€¦',
    statusPhotoReady: 'Photo ready. Pick a prompt to continue.',
    statusInvalidFile: 'Please select an image file (jpg, png, heic).',
    statusFileTooLarge: 'Image must be 10MB or less.',
    statusNeedPhoto: 'Please upload a photo first.',
    statusNeedPrompt: 'Prompt cannot be empty.',
    statusAnalyzing: 'Sending image to Glamaâ€¦',
    statusAnalyzeComplete: 'Vision analysis complete.',
    statusAnalyzeFailed: 'Vision analysis failed.',
    summaryHeading: 'Vision summary',
    summaryEmpty: 'No analysis yet.',
    objectsHeading: 'Detected objects',
    objectsSubheading: 'Top items, sorted by model confidence.',
    objectsEmpty: 'No objects returned.',
    rawHeading: 'Raw payload',
    rawSubheading: 'Direct JSON from the Glama response.',
    rawPlaceholder: '// Awaiting responseâ€¦',
    chatHeading: 'Ask about this analysis',
    chatSubheading: 'Once a photo is analyzed, ask follow-up questions here.',
    chatPlaceholder: 'Type a question in your languageâ€¦',
    chatSendButton: 'Ask',
    chatUserLabel: 'You',
    chatAssistantLabel: 'Vision analyst',
    chatEmpty: 'Chat is ready as soon as you run an analysis.',
    chatThinking: 'Thinkingâ€¦',
    chatError: 'Sorry, I couldnâ€™t answer that.',
    chatPresetSummary: 'Quick summary',
    chatPresetSummaryText: 'Give me a 2 sentence summary of the detections.',
    chatPresetAnomalies: 'Policy & safety issues',
    chatPresetAnomaliesText: 'List any compliance or safety issues that showed up.',
    chatPresetNextSteps: 'Actionable next steps',
    chatPresetNextStepsText: 'What are the top 3 actions we should take next based on this scene?',
    chatPresetInventory: 'Inventory counts',
    chatPresetInventoryText: 'Report notable inventory levels or items that look empty or overstocked.',
    chatPresetRisks: 'Risk factors',
    chatPresetRisksText: 'Call out any potential risks or hazards in this scene and why they matter.',
    statusNeedAnalysis: 'Run a describe + detect first, then start a chat.'
  },
  th: {
    heroEyebrow: 'à¹€à¸‹à¸´à¸£à¹Œà¸Ÿà¹„à¸—à¸¢à¹à¸¥à¸™à¸”à¹Œ â€¢ à¸Šà¸¸à¸”à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­à¸§à¸´à¸Šà¸±à¹ˆà¸™ A1',
    heroTitle: 'à¸ªà¸™à¸²à¸¡à¸—à¸”à¸¥à¸­à¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸ à¸²à¸ž',
    heroLede:
      'à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸ à¸²à¸žà¸™à¸´à¹ˆà¸‡ à¹€à¸¥à¸·à¸­à¸à¸žà¸£à¸­à¸¡à¸•à¹Œà¸§à¸´à¸Šà¸±à¹ˆà¸™ à¹à¸¥à¹‰à¸§à¹€à¸£à¸²à¸ˆà¸°à¸ªà¹ˆà¸‡à¹„à¸›à¸¢à¸±à¸‡ Glama à¹€à¸žà¸·à¹ˆà¸­à¸šà¸£à¸£à¸¢à¸²à¸¢à¸‰à¸²à¸à¹à¸¥à¸°à¹€à¸™à¹‰à¸™à¸§à¸±à¸•à¸–à¸¸à¸ªà¸³à¸„à¸±à¸à¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸—à¸±à¸™à¸—à¸µ',
    langLabel: 'à¸ à¸²à¸©à¸²',
    uploadHeading: '1. à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸ à¸²à¸ž',
    uploadBody: 'à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸žà¸™à¸´à¹ˆà¸‡ 1 à¹„à¸Ÿà¸¥à¹Œ à¸‚à¸™à¸²à¸”à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 10â€¯MB à¸ˆà¸°à¹€à¸›à¹‡à¸™à¹à¸™à¸§à¸•à¸±à¹‰à¸‡à¸«à¸£à¸·à¸­à¹à¸™à¸§à¸™à¸­à¸™à¸à¹‡à¹„à¸”à¹‰',
    dropTitle: 'à¸¥à¸²à¸ & à¸§à¸²à¸‡à¸£à¸¹à¸›à¸ à¸²à¸ž',
    dropAlt: 'à¸«à¸£à¸·à¸­',
    browseButton: 'à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ',
    cameraButton: 'à¸–à¹ˆà¸²à¸¢à¸£à¸¹à¸›',
    fileHintEmpty: 'à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ',
    promptHeading: '2. à¹€à¸¥à¸·à¸­à¸à¹‚à¸ˆà¸—à¸¢à¹Œà¸§à¸´à¸Šà¸±à¹ˆà¸™',
    promptBody: 'à¹à¸•à¸°à¸Šà¸´à¸›à¹€à¸žà¸·à¹ˆà¸­à¸à¸£à¸­à¸à¸žà¸£à¸­à¸¡à¸•à¹Œà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ à¸«à¸£à¸·à¸­à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹€à¸­à¸‡',
    modelLabel: 'à¹‚à¸¡à¹€à¸”à¸¥à¸§à¸´à¸Šà¸±à¹ˆà¸™',
    modelTagLabel: 'LLM',
    latencyLabel: 'à¸„à¸§à¸²à¸¡à¸«à¸™à¹ˆà¸§à¸‡',
    promptLabel: 'à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡',
    promptPlaceholder: 'à¸­à¸˜à¸´à¸šà¸²à¸¢à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸­à¸¢à¸²à¸à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥à¹‚à¸Ÿà¸à¸±à¸ªâ€¦',
    analyzeButtonIdle: 'à¸ªà¸±à¹ˆà¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸ à¸²à¸ž',
    analyzeButtonBusy: 'à¸à¸³à¸¥à¸±à¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œâ€¦',
    statusWaiting: 'à¸£à¸­à¸£à¸¹à¸›à¸ à¸²à¸žà¸ˆà¸²à¸à¸„à¸¸à¸“â€¦',
    statusPhotoReady: 'à¹„à¸Ÿà¸¥à¹Œà¸žà¸£à¹‰à¸­à¸¡à¹à¸¥à¹‰à¸§ à¹€à¸¥à¸·à¸­à¸à¸žà¸£à¸­à¸¡à¸•à¹Œà¸•à¹ˆà¸­à¹„à¸”à¹‰à¹€à¸¥à¸¢',
    statusInvalidFile: 'à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œà¸ à¸²à¸ž (jpg, png, heic)',
    statusFileTooLarge: 'à¹„à¸Ÿà¸¥à¹Œà¸•à¹‰à¸­à¸‡à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 10â€¯MB',
    statusNeedPhoto: 'à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸ à¸²à¸žà¸à¹ˆà¸­à¸™',
    statusNeedPrompt: 'à¸«à¹‰à¸²à¸¡à¸›à¸¥à¹ˆà¸­à¸¢à¸žà¸£à¸­à¸¡à¸•à¹Œà¸§à¹ˆà¸²à¸‡',
    statusAnalyzing: 'à¸à¸³à¸¥à¸±à¸‡à¸ªà¹ˆà¸‡à¸ à¸²à¸žà¹„à¸›à¸¢à¸±à¸‡ Glamaâ€¦',
    statusAnalyzeComplete: 'à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸ à¸²à¸žà¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§',
    statusAnalyzeFailed: 'à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸ à¸²à¸žà¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ',
    summaryHeading: 'à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸§à¸´à¸Šà¸±à¹ˆà¸™',
    summaryEmpty: 'à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ',
    objectsHeading: 'à¸§à¸±à¸•à¸–à¸¸à¸—à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¸žà¸š',
    objectsSubheading: 'à¹€à¸£à¸µà¸¢à¸‡à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥',
    objectsEmpty: 'à¹„à¸¡à¹ˆà¸¡à¸µà¸§à¸±à¸•à¸–à¸¸à¸—à¸µà¹ˆà¸£à¸²à¸¢à¸‡à¸²à¸™',
    rawHeading: 'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸”à¸´à¸š',
    rawSubheading: 'JSON à¸•à¸£à¸‡à¸ˆà¸²à¸à¸à¸²à¸£à¸•à¸­à¸šà¸à¸¥à¸±à¸šà¸‚à¸­à¸‡ Glama',
    rawPlaceholder: '// à¸£à¸­à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œâ€¦',
    chatHeading: 'à¸–à¸²à¸¡à¸•à¹ˆà¸­à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸™à¸µà¹‰',
    chatSubheading: 'à¹€à¸¡à¸·à¹ˆà¸­à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸ à¸²à¸žà¹à¸¥à¹‰à¸§ à¸žà¸´à¸¡à¸žà¹Œà¸„à¸³à¸–à¸²à¸¡à¸•à¸´à¸”à¸•à¸²à¸¡à¹„à¸”à¹‰à¸—à¸µà¹ˆà¸™à¸µà¹ˆ',
    chatPlaceholder: 'à¸žà¸´à¸¡à¸žà¹Œà¸„à¸³à¸–à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¸‚à¸­à¸‡à¸„à¸¸à¸“â€¦',
    chatSendButton: 'à¸–à¸²à¸¡',
    chatUserLabel: 'à¸„à¸¸à¸“',
    chatAssistantLabel: 'à¸™à¸±à¸à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ',
    chatEmpty: 'à¸žà¸£à¹‰à¸­à¸¡à¹à¸Šà¸—à¸—à¸±à¸™à¸—à¸µà¸«à¸¥à¸±à¸‡à¸ªà¸±à¹ˆà¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ',
    chatThinking: 'à¸à¸³à¸¥à¸±à¸‡à¸„à¸´à¸”â€¦',
    chatError: 'à¸‚à¸­à¸­à¸ à¸±à¸¢ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸™à¸µà¹‰à¹„à¸”à¹‰',
    chatPresetSummary: 'à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ',
    chatPresetSummaryText: 'à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ 2 à¸›à¸£à¸°à¹‚à¸¢à¸„',
    chatPresetAnomalies: 'à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢',
    chatPresetAnomaliesText: 'à¸£à¸°à¸šà¸¸à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸‚à¸¶à¹‰à¸™',
    chatPresetNextSteps: 'à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸•à¹ˆà¸­à¹„à¸›',
    chatPresetNextStepsText: 'à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸•à¹ˆà¸­à¹„à¸› 3 à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™',
    chatPresetInventory: 'à¸ªà¸´à¸™à¸„à¹‰à¸²à¸„à¸‡à¸„à¸¥à¸±à¸‡',
    chatPresetInventoryText: 'à¸£à¸²à¸¢à¸‡à¸²à¸™à¸ªà¸´à¸™à¸„à¹‰à¸²à¸„à¸‡à¸„à¸¥à¸±à¸‡',
    chatPresetRisks: 'à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡',
    chatPresetRisksText: 'à¸£à¸°à¸šà¸¸à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡à¹à¸¥à¸°à¹€à¸«à¸•à¸¸à¸œà¸¥',
    statusNeedAnalysis: 'à¸à¸£à¸¸à¸“à¸²à¸ªà¸±à¹ˆà¸‡ describe + detect à¸à¹ˆà¸­à¸™à¹à¸¥à¹‰à¸§à¸„à¹ˆà¸­à¸¢à¹€à¸£à¸´à¹ˆà¸¡à¹à¸Šà¸—'
  },
  de: {
    heroEyebrow: 'Surf Thailand â€¢ A1 Vision-Werkzeuge',
    heroTitle: 'Sandbox fÃ¼r BildverstÃ¤ndnis',
    heroLede:
      'Lade ein Standbild hoch, wÃ¤hle einen Vision-Prompt und wir schicken es Ã¼ber Glama, um die Szene zu beschreiben und Objekte hervorzuheben.',
    langLabel: 'Sprache',
    uploadHeading: '1. Foto hochladen',
    uploadBody: 'Ein einzelnes Bild, max. 10â€¯MB. Funktioniert im Hoch- oder Querformat.',
    dropTitle: 'Foto ziehen & ablegen',
    dropAlt: 'oder',
    browseButton: 'Datei wÃ¤hlen',
    cameraButton: 'Foto aufnehmen',
    fileHintEmpty: 'Noch kein Foto ausgewÃ¤hlt.',
    promptHeading: '2. Vision-Brief wÃ¤hlen',
    promptBody: 'Tippe einen Chip an, um den Prompt zu fÃ¼llen, oder passe den Text an.',
    modelLabel: 'Vision-Modell',
    modelTagLabel: 'LLM',
    latencyLabel: 'Latenz',
    promptLabel: 'Eigene Anweisungen',
    promptPlaceholder: 'ErklÃ¤re, worauf das Modell achten sollâ€¦',
    analyzeButtonIdle: 'Analyse starten',
    analyzeButtonBusy: 'Analysiereâ€¦',
    statusWaiting: 'Warte auf dein Fotoâ€¦',
    statusPhotoReady: 'Foto bereit. WÃ¤hle einen Prompt.',
    statusInvalidFile: 'Bitte eine Bilddatei wÃ¤hlen (jpg, png, heic).',
    statusFileTooLarge: 'Bild muss 10â€¯MB oder kleiner sein.',
    statusNeedPhoto: 'Bitte zuerst ein Foto hochladen.',
    statusNeedPrompt: 'Prompt darf nicht leer sein.',
    statusAnalyzing: 'Sende Bild an Glamaâ€¦',
    statusAnalyzeComplete: 'Vision-Analyse abgeschlossen.',
    statusAnalyzeFailed: 'Vision-Analyse fehlgeschlagen.',
    summaryHeading: 'Vision-Zusammenfassung',
    summaryEmpty: 'Noch keine Analyse.',
    objectsHeading: 'Erkannte Objekte',
    objectsSubheading: 'Top-Ergebnisse nach Modellvertrauen sortiert.',
    objectsEmpty: 'Keine Objekte geliefert.',
    rawHeading: 'Rohdaten',
    rawSubheading: 'Direktes JSON aus der Glama-Antwort.',
    rawPlaceholder: '// Warte auf Ergebnisâ€¦',
    chatHeading: 'Fragen zur Analyse',
    chatSubheading: 'Nach der Fotoanalyse kannst du hier RÃ¼ckfragen stellen.',
    chatPlaceholder: 'Stelle deine Frage in deiner Spracheâ€¦',
    chatSendButton: 'Fragen',
    chatUserLabel: 'Du',
    chatAssistantLabel: 'Vision-Analyst',
    chatEmpty: 'Starte zuerst eine Analyse, dann ist der Chat bereit.',
    chatThinking: 'Denke nachâ€¦',
    chatError: 'Sorry, ich konnte das nicht beantworten.',
    chatPresetSummary: 'Zusammenfassung',
    chatPresetSummaryText: 'Gib mir eine 2-Satz-Zusammenfassung der Ergebnisse.',
    chatPresetAnomalies: 'Sicherheitsprobleme',
    chatPresetAnomaliesText: 'Liste alle Sicherheitsprobleme auf.',
    chatPresetNextSteps: 'NÃ¤chste Schritte',
    chatPresetNextStepsText: 'Was sind die nÃ¤chsten 3 Schritte, die wir unternehmen sollten?',
    chatPresetInventory: 'Inventar',
    chatPresetInventoryText: 'Berichte Ã¼ber das Inventar.',
    chatPresetRisks: 'Risiken',
    chatPresetRisksText: 'Benenne alle Risiken und ihre GrÃ¼nde.',
    statusNeedAnalysis: 'FÃ¼hre zuerst eine Analyse durch, bevor du den Chat startest.'
  },
  no: {
    heroEyebrow: 'Surf Thailand â€¢ A1 VisionverktÃ¸y',
    heroTitle: 'Sandkasse for bildeforstÃ¥else',
    heroLede:
      'Last opp et stillbilde, velg en visjonsprompt, sÃ¥ sender vi det via Glama for Ã¥ beskrive scenen og finne objekter.',
    langLabel: 'SprÃ¥k',
    uploadHeading: '1. Last opp bilde',
    uploadBody: 'Ett stillbilde, maks 10â€¯MB. Fungerer i stÃ¥ende eller liggende format.',
    dropTitle: 'Dra og slipp bilde',
    dropAlt: 'eller',
    browseButton: 'velg filer',
    cameraButton: 'ta et bilde',
    fileHintEmpty: 'Ingen fil valgt ennÃ¥.',
    promptHeading: '2. Velg en visjonsbrief',
    promptBody: 'Trykk pÃ¥ en chip for Ã¥ fylle prompten, eller finjuster teksten.',
    modelLabel: 'Visjonsmodell',
    modelTagLabel: 'LLM',
    latencyLabel: 'Latens',
    promptLabel: 'Egne instruksjoner',
    promptPlaceholder: 'Forklar hva modellen skal fokusere pÃ¥â€¦',
    analyzeButtonIdle: 'KjÃ¸r beskriv + detekter',
    analyzeButtonBusy: 'Analysererâ€¦',
    statusWaiting: 'Venter pÃ¥ bildet dittâ€¦',
    statusPhotoReady: 'Bilde klart. Velg en prompt.',
    statusInvalidFile: 'Velg en bildefil (jpg, png, heic).',
    statusFileTooLarge: 'Bildet mÃ¥ vÃ¦re 10â€¯MB eller mindre.',
    statusNeedPhoto: 'Last opp et bilde fÃ¸rst.',
    statusNeedPrompt: 'Prompt kan ikke vÃ¦re tom.',
    statusAnalyzing: 'Sender bilde til Glamaâ€¦',
    statusAnalyzeComplete: 'Visjonsanalyse fullfÃ¸rt.',
    statusAnalyzeFailed: 'Visjonsanalyse feilet.',
    summaryHeading: 'Visjonsoppsummering',
    summaryEmpty: 'Ingen analyse ennÃ¥.',
    objectsHeading: 'Oppdagede objekter',
    objectsSubheading: 'Viktigste funn sortert pÃ¥ modellens trygghet.',
    objectsEmpty: 'Ingen objekter returnert.',
    rawHeading: 'RÃ¥data',
    rawSubheading: 'JSON direkte fra Glama-responsen.',
    rawPlaceholder: '// Venter pÃ¥ svarâ€¦',
    chatHeading: 'Still spÃ¸rsmÃ¥l om analysen',
    chatSubheading: 'NÃ¥r bildet er analysert kan du stille oppfÃ¸lgingsspÃ¸rsmÃ¥l her.',
    chatPlaceholder: 'Skriv et spÃ¸rsmÃ¥l pÃ¥ ditt sprÃ¥kâ€¦',
    chatSendButton: 'SpÃ¸r',
    chatUserLabel: 'Du',
    chatAssistantLabel: 'Visjonsanalytiker',
    chatEmpty: 'KjÃ¸r en analyse fÃ¸rst, sÃ¥ er chatten klar.',
    chatThinking: 'Tenkerâ€¦',
    chatError: 'Jeg klarte ikke Ã¥ svare pÃ¥ det.',
    chatPresetSummary: 'Oppsummering',
    chatPresetSummaryText: 'Gi meg en 2-setninger oppsummering av resultatene.',
    chatPresetAnomalies: 'Sikkerhetsproblemer',
    chatPresetAnomaliesText: 'Liste alle sikkerhetsproblemer.',
    chatPresetNextSteps: 'Neste steg',
    chatPresetNextStepsText: 'Hva er de neste 3 stegene vi bÃ¸r ta?',
    chatPresetInventory: 'Inventar',
    chatPresetInventoryText: 'Rapporter om inventaret.',
    chatPresetRisks: 'Risiko',
    chatPresetRisksText: 'Navngi alle risiko og deres Ã¥rsaker.',
    statusNeedAnalysis: 'KjÃ¸r en analyse fÃ¸rst, sÃ¥ starter du chatten.'
  },
  sv: {
    heroEyebrow: 'Surf Thailand â€¢ A1 Visionverktyg',
    heroTitle: 'SandlÃ¥da fÃ¶r bildfÃ¶rstÃ¥else',
    heroLede:
      'Ladda upp ett stillbild, vÃ¤lj en visionbrief sÃ¥ skickar vi det via Glama fÃ¶r att beskriva scenen och hitta objekt.',
    langLabel: 'SprÃ¥k',
    uploadHeading: '1. Ladda upp foto',
    uploadBody: 'Ett stillbild, max 10â€¯MB. Fungerar i stÃ¥ende eller liggande lÃ¤ge.',
    dropTitle: 'Dra & slÃ¤pp foto',
    dropAlt: 'eller',
    browseButton: 'blÃ¤ddra filer',
    cameraButton: 'ta ett foto',
    fileHintEmpty: 'Ingen fil vald Ã¤nnu.',
    promptHeading: '2. VÃ¤lj en visionbrief',
    promptBody: 'Tryck pÃ¥ en chip fÃ¶r att fylla prompten eller finjustera texten.',
    modelLabel: 'Visionmodell',
    modelTagLabel: 'LLM',
    latencyLabel: 'Latens',
    promptLabel: 'Egna instruktioner',
    promptPlaceholder: 'BerÃ¤tta vad modellen ska fokusera pÃ¥â€¦',
    analyzeButtonIdle: 'KÃ¶r beskriv + detektera',
    analyzeButtonBusy: 'Analyserarâ€¦',
    statusWaiting: 'VÃ¤ntar pÃ¥ ditt fotoâ€¦',
    statusPhotoReady: 'Foto klart. VÃ¤lj en prompt.',
    statusInvalidFile: 'VÃ¤lj en bildfil (jpg, png, heic).',
    statusFileTooLarge: 'Bilden mÃ¥ste vara 10â€¯MB eller mindre.',
    statusNeedPhoto: 'Ladda upp ett foto fÃ¶rst.',
    statusNeedPrompt: 'Prompten fÃ¥r inte vara tom.',
    statusAnalyzing: 'Skickar bilden till Glamaâ€¦',
    statusAnalyzeComplete: 'Visionanalysen Ã¤r klar.',
    statusAnalyzeFailed: 'Visionanalysen misslyckades.',
    summaryHeading: 'Visionssammanfattning',
    summaryEmpty: 'Ingen analys Ã¤nnu.',
    objectsHeading: 'UpptÃ¤ckta objekt',
    objectsSubheading: 'Toppobjekt sorterade efter modellens sÃ¤kerhet.',
    objectsEmpty: 'Inga objekt returnerades.',
    rawHeading: 'RÃ¥payload',
    rawSubheading: 'JSON direkt frÃ¥n Glama-svaret.',
    rawPlaceholder: '// VÃ¤ntar pÃ¥ svarâ€¦',
    chatHeading: 'FrÃ¥ga om analysen',
    chatSubheading: 'NÃ¤r bilden Ã¤r analyserad kan du stÃ¤lla fÃ¶ljdfrÃ¥gor hÃ¤r.',
    chatPlaceholder: 'Skriv en frÃ¥ga pÃ¥ ditt sprÃ¥kâ€¦',
    chatSendButton: 'FrÃ¥ga',
    chatUserLabel: 'Du',
    chatAssistantLabel: 'Visionanalytiker',
    chatEmpty: 'KÃ¶r en analys fÃ¶rst sÃ¥ aktiveras chatten.',
    chatThinking: 'TÃ¤nkerâ€¦',
    chatError: 'TyvÃ¤rr kunde jag inte svara pÃ¥ det.',
    statusNeedAnalysis: 'KÃ¶r beskriv + detektera innan du anvÃ¤nder chatten.'
  },
  es: {
    heroEyebrow: 'Surf Tailandia â€¢ Utilidades A1 Vision',
    heroTitle: 'Laboratorio de comprensiÃ³n visual',
    heroLede:
      'Sube una foto fija, elige un prompt de visiÃ³n y la enviaremos por Glama para describir la escena y seÃ±alar objetos clave.',
    langLabel: 'Idioma',
    uploadHeading: '1. Subir foto',
    uploadBody: 'Imagen fija Ãºnica, mÃ¡ximo 10â€¯MB. Funciona en vertical u horizontal.',
    dropTitle: 'Arrastra y suelta la foto',
    dropAlt: 'o',
    browseButton: 'explorar archivos',
    cameraButton: 'tomar una foto',
    fileHintEmpty: 'AÃºn no hay archivo seleccionado.',
    promptHeading: '2. Elige un brief de visiÃ³n',
    promptBody: 'Toca un chip para autocompletar el prompt o ajusta el texto manualmente.',
    modelLabel: 'Modelo de visiÃ³n',
    modelTagLabel: 'LLM',
    latencyLabel: 'Latencia',
    promptLabel: 'Instrucciones personalizadas',
    promptPlaceholder: 'Explica en quÃ© debe enfocarse el modeloâ€¦',
    analyzeButtonIdle: 'Ejecutar describir + detectar',
    analyzeButtonBusy: 'Analizandoâ€¦',
    statusWaiting: 'Esperando tu fotoâ€¦',
    statusPhotoReady: 'Foto lista. Elige un prompt.',
    statusInvalidFile: 'Selecciona un archivo de imagen (jpg, png, heic).',
    statusFileTooLarge: 'La imagen debe pesar 10â€¯MB o menos.',
    statusNeedPhoto: 'Primero sube una foto.',
    statusNeedPrompt: 'El prompt no puede estar vacÃ­o.',
    statusAnalyzing: 'Enviando imagen a Glamaâ€¦',
    statusAnalyzeComplete: 'AnÃ¡lisis de visiÃ³n completo.',
    statusAnalyzeFailed: 'El anÃ¡lisis de visiÃ³n fallÃ³.',
    summaryHeading: 'Resumen de visiÃ³n',
    summaryEmpty: 'AÃºn no hay anÃ¡lisis.',
    objectsHeading: 'Objetos detectados',
    objectsSubheading: 'Elementos principales ordenados por confianza del modelo.',
    objectsEmpty: 'No se devolvieron objetos.',
    rawHeading: 'Datos sin procesar',
    rawSubheading: 'JSON directo de la respuesta de Glama.',
    rawPlaceholder: '// Esperando respuestaâ€¦',
    chatHeading: 'Pregunta sobre la detecciÃ³n',
    chatSubheading: 'Cuando la foto estÃ© analizada, haz tus preguntas de seguimiento aquÃ­.',
    chatPlaceholder: 'Escribe tu pregunta en tu idiomaâ€¦',
    chatSendButton: 'Preguntar',
    chatUserLabel: 'TÃº',
    chatAssistantLabel: 'Analista de visiÃ³n',
    chatEmpty: 'Ejecuta un anÃ¡lisis primero para habilitar el chat.',
    chatThinking: 'Pensandoâ€¦',
    chatError: 'No pude responder eso.',
    statusNeedAnalysis: 'Ejecuta describir + detectar antes de iniciar el chat.'
  },
  ja: {
    heroEyebrow: 'Surf Thailand â€¢ A1 ãƒ“ã‚¸ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«',
    heroTitle: 'ç”»åƒç†è§£ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹',
    heroLede:
      'é™æ­¢ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ“ã‚¸ãƒ§ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸ã¶ã ã‘ã§ã€Glama ãŒã‚·ãƒ¼ãƒ³ã‚’èª¬æ˜Žã—æ³¨ç›®ã™ã¹ãç‰©ä½“ã‚’ç¤ºã—ã¾ã™ã€‚',
    langLabel: 'è¨€èªž',
    uploadHeading: '1. å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰',
    uploadBody: 'é™æ­¢ç”» 1 æžšã€æœ€å¤§ 10â€¯MBã€‚ç¸¦æ¨ªã©ã¡ã‚‰ã®å†™çœŸã§ã‚‚OKã§ã™ã€‚',
    dropTitle: 'ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—',
    dropAlt: 'ã¾ãŸã¯',
    browseButton: 'ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠž',
    cameraButton: 'å†™çœŸã‚’æ’®ã‚‹',
    fileHintEmpty: 'ã¾ã ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠžã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚',
    promptHeading: '2. ãƒ“ã‚¸ãƒ§ãƒ³ãƒ–ãƒªãƒ¼ãƒ•ã‚’é¸æŠž',
    promptBody: 'ãƒãƒƒãƒ—ã‚’æŠ¼ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•å…¥åŠ›ã™ã‚‹ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚',
    modelLabel: 'ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«',
    modelTagLabel: 'LLM',
    latencyLabel: 'ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·',
    promptLabel: 'ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤º',
    promptPlaceholder: 'ãƒ¢ãƒ‡ãƒ«ã«æ³¨ç›®ã—ã¦ã»ã—ã„ç‚¹ã‚’èª¬æ˜Žã—ã¦ãã ã•ã„â€¦',
    analyzeButtonIdle: 'è§£æžã‚’å®Ÿè¡Œ',
    analyzeButtonBusy: 'è§£æžä¸­â€¦',
    statusWaiting: 'å†™çœŸã‚’å¾…ã£ã¦ã„ã¾ã™â€¦',
    statusPhotoReady: 'å†™çœŸã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠžã—ã¦ãã ã•ã„ã€‚',
    statusInvalidFile: 'ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆjpg, png, heicï¼‰ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚',
    statusFileTooLarge: 'ç”»åƒã¯ 10â€¯MB ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ã€‚',
    statusNeedPhoto: 'ã¾ãšå†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚',
    statusNeedPrompt: 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç©ºã«ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚',
    statusAnalyzing: 'Glama ã«é€ä¿¡ã—ã¦ã„ã¾ã™â€¦',
    statusAnalyzeComplete: 'ãƒ“ã‚¸ãƒ§ãƒ³è§£æžãŒå®Œäº†ã—ã¾ã—ãŸã€‚',
    statusAnalyzeFailed: 'ãƒ“ã‚¸ãƒ§ãƒ³è§£æžã«å¤±æ•—ã—ã¾ã—ãŸã€‚',
    summaryHeading: 'ãƒ“ã‚¸ãƒ§ãƒ³ã‚µãƒžãƒªãƒ¼',
    summaryEmpty: 'ã¾ã è§£æžãŒã‚ã‚Šã¾ã›ã‚“ã€‚',
    objectsHeading: 'æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ',
    objectsSubheading: 'ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼åº¦ã§ä¸¦ã¹ãŸä¸Šä½ã‚¢ã‚¤ãƒ†ãƒ ã€‚',
    objectsEmpty: 'ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯è¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚',
    rawHeading: 'ç”Ÿãƒ‡ãƒ¼ã‚¿',
    rawSubheading: 'Glama å¿œç­”ã® JSON ã‚’ãã®ã¾ã¾è¡¨ç¤ºã—ã¾ã™ã€‚',
    rawPlaceholder: '// çµæžœã‚’å¾…æ©Ÿä¸­â€¦',
    chatHeading: 'ã“ã®è§£æžã«ã¤ã„ã¦è³ªå•ã™ã‚‹',
    chatSubheading: 'å†™çœŸã‚’è§£æžã—ãŸå¾Œã¯ã€ã“ã“ã§è¿½è³ªå•ãŒã§ãã¾ã™ã€‚',
    chatPlaceholder: 'ã‚ãªãŸã®è¨€èªžã§è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„â€¦',
    chatSendButton: 'è³ªå•ã™ã‚‹',
    chatUserLabel: 'ã‚ãªãŸ',
    chatAssistantLabel: 'ãƒ“ã‚¸ãƒ§ãƒ³ã‚¢ãƒŠãƒªã‚¹ãƒˆ',
    chatEmpty: 'ã¾ãšè§£æžã‚’å®Ÿè¡Œã™ã‚‹ã¨ãƒãƒ£ãƒƒãƒˆãŒåˆ©ç”¨ã§ãã¾ã™ã€‚',
    chatThinking: 'è€ƒãˆã¦ã„ã¾ã™â€¦',
    chatError: 'ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å›žç­”ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚',
    statusNeedAnalysis: 'å…ˆã« describe + detect ã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚'
  },
  zh: {
    heroEyebrow: 'Surf Thailand â€¢ A1 è§†è§‰å·¥å…·',
    heroTitle: 'å›¾åƒç†è§£æ²™ç›’',
    heroLede:
      'ä¸Šä¼ ä¸€å¼ é™æ€ç…§ç‰‡ï¼Œé€‰æ‹©ä¸€ä¸ªè§†è§‰æç¤ºï¼Œæˆ‘ä»¬ä¼šé€šè¿‡ Glama è§†è§‰æŽ¥å£æè¿°åœºæ™¯å¹¶æ ‡è®°é‡ç‚¹ç‰©ä½“ã€‚',
    langLabel: 'è¯­è¨€',
    uploadHeading: '1. ä¸Šä¼ ç…§ç‰‡',
    uploadBody: 'ä»…é™å•å¼ é™æ€å›¾ç‰‡ï¼Œæœ€å¤§ 10â€¯MBï¼Œç«–å±æ¨ªå±éƒ½æ”¯æŒã€‚',
    dropTitle: 'æ‹–æ‹½ä¸Šä¼ ç…§ç‰‡',
    dropAlt: 'æˆ–',
    browseButton: 'æµè§ˆæ–‡ä»¶',
    cameraButton: 'æ‹æ‘„ç…§ç‰‡',
    fileHintEmpty: 'å°šæœªé€‰æ‹©æ–‡ä»¶ã€‚',
    promptHeading: '2. é€‰æ‹©è§†è§‰ä»»åŠ¡',
    promptBody: 'ç‚¹å‡»èŠ¯ç‰‡è‡ªåŠ¨å¡«å……æç¤ºï¼Œä¹Ÿå¯ä»¥åœ¨è¾“å…¥æ¡†ä¸­å¾®è°ƒã€‚',
    modelLabel: 'è§†è§‰æ¨¡åž‹',
    analyzeButtonBusy: 'åˆ†æžä¸­â€¦',
    statusWaiting: 'ç­‰å¾…ä½ çš„ç…§ç‰‡â€¦',
    statusPhotoReady: 'ç…§ç‰‡å°±ç»ªï¼Œç»§ç»­é€‰æ‹©æç¤ºã€‚',
    statusInvalidFile: 'è¯·é€‰æ‹©å›¾ç‰‡æ–‡ä»¶ï¼ˆjpgã€pngã€heicï¼‰ã€‚',
    statusFileTooLarge: 'å›¾ç‰‡å¿…é¡»å°äºŽæˆ–ç­‰äºŽ 10â€¯MBã€‚',
    statusNeedPhoto: 'è¯·å…ˆä¸Šä¼ ç…§ç‰‡ã€‚',
    statusNeedPrompt: 'æç¤ºä¸èƒ½ä¸ºç©ºã€‚',
    statusAnalyzing: 'æ­£åœ¨å°†å›¾ç‰‡å‘é€åˆ° Glamaâ€¦',
    statusAnalyzeComplete: 'è§†è§‰åˆ†æžå®Œæˆã€‚',
    statusAnalyzeFailed: 'è§†è§‰åˆ†æžå¤±è´¥ã€‚',
    summaryHeading: 'è§†è§‰æ‘˜è¦',
    summaryEmpty: 'å°šæ— åˆ†æžç»“æžœã€‚',
    objectsHeading: 'æ£€æµ‹åˆ°çš„ç‰©ä½“',
    objectsSubheading: 'æŒ‰æ¨¡åž‹ç½®ä¿¡åº¦æŽ’åºçš„é‡ç‚¹é¡¹ç›®ã€‚',
    objectsEmpty: 'æœªè¿”å›žä»»ä½•ç‰©ä½“ã€‚',
    rawHeading: 'åŽŸå§‹æ•°æ®',
    rawSubheading: 'æ¥è‡ª Glama å“åº”çš„ JSONã€‚',
    rawPlaceholder: '// æ­£åœ¨ç­‰å¾…å“åº”â€¦',
    chatHeading: 'å°±æœ¬æ¬¡åˆ†æžæé—®',
    chatSubheading: 'ç…§ç‰‡åˆ†æžå®ŒæˆåŽï¼Œå¯åœ¨æ­¤æå‡ºè¿½é—®ã€‚',
    chatPlaceholder: 'ç”¨ä½ çš„è¯­è¨€è¾“å…¥é—®é¢˜â€¦',
    chatSendButton: 'æé—®',
    chatUserLabel: 'ä½ ',
    chatAssistantLabel: 'è§†è§‰åˆ†æžå¸ˆ',
    chatEmpty: 'å…ˆè¿è¡Œä¸€æ¬¡åˆ†æžå³å¯å¯ç”¨èŠå¤©ã€‚',
    chatThinking: 'æ€è€ƒä¸­â€¦',
    chatError: 'æŠ±æ­‰ï¼Œæ— æ³•å›žç­”è¯¥é—®é¢˜ã€‚',
    statusNeedAnalysis: 'è¯·å…ˆæ‰§è¡Œæè¿°+æ£€æµ‹ï¼Œå†å¼€å§‹èŠå¤©ã€‚'
  },
  ko: [
    {
      id: 'urban',
      label: 'ë„ë¡œ ìš´ì˜ ì ê²€',
      text: 'êµí†µ íë¦„, í‘œì§€ ìƒíƒœ, êµ°ì¤‘ í–‰ë™ì„ ì„¤ëª…í•˜ê³  ê±°ë¦¬ì˜ ì •ì „ì´ë‚˜ ìœ„í—˜ ìš”ì†Œë¥¼ í‘œì‹œí•˜ì„¸ìš”.'
    },
    {
      id: 'retail',
      label: 'ë§¤ìž¥ ì»´í”Œë¼ì´ì–¸ìŠ¤ ê²€ì‚¬',
      text: 'ì§„ì—´ ìƒíƒœ, í”„ë¡œëª¨ì…˜ ë””ìŠ¤í”Œë ˆì´, ì§ì›Â·ê³ ê° ìƒí˜¸ìž‘ìš©ì„ ì ê²€í•´ ë§¤ìž¥ ì‹¤í–‰ë ¥ì„ í‰ê°€í•˜ì„¸ìš”.'
    },
    {
      id: 'safety',
      label: 'ì•ˆì „ ìˆœì°°',
      text: 'PPE ì°©ìš©, ë§‰ížŒ ë¹„ìƒêµ¬, ìœ ì¶œ ë“± ì•ˆì „ ê·œì • ìœ„ë°˜ì„ ì°¾ì•„ì£¼ì„¸ìš”.'
    },
    {
      id: 'vehicle',
      label: 'ì°¨ëŸ‰ ì†ìƒ ì¡°ì‚¬',
      text: 'ì°¨ì²´, ìœ ë¦¬, ì¡°ëª…ì„ ì‚´íŽ´ë³´ê³  ì°Œê·¸ëŸ¬ì§, í ì§‘, ë…¹, ëˆ„ë½ëœ ë¶€í’ˆê³¼ ë²ˆí˜¸íŒ ì •ë³´ë¥¼ ë³´ê³ í•˜ì„¸ìš”.'
    },
    {
      id: 'receipt',
      label: 'ì˜ìˆ˜ì¦/ì „í‘œ ì¶”ì¶œ',
      text: 'ì´ì•¡, ì„¸ê¸ˆ, ë§¤ìž¥ ì •ë³´, ê²°ì œ ìˆ˜ë‹¨, ì†ê¸€ì”¨ ë©”ëª¨ë¥¼ ì „ì‚¬í•˜ì„¸ìš”.'
    },
    {
      id: 'manual',
      label: 'ë§¤ë‰´ì–¼/SOP ìš”ì•½',
      text: 'ë¬¸ì„œ ëª©ì , í•µì‹¬ ë‹¨ê³„, ê²½ê³ , ì–¸ê¸‰ëœ ë„êµ¬ë¥¼ ìš”ì•½í•˜ì„¸ìš”.'
    },
    {
      id: 'specsheet',
      label: 'ê¸°ìˆ  ì‚¬ì–‘ í•˜ì´ë¼ì´íŠ¸',
      text: 'ëª¨ë¸ ë²ˆí˜¸, ì£¼ìš” ì‚¬ì–‘(ì „ë ¥, ì¹˜ìˆ˜, ì†Œìž¬), ì¸ì¦ ë° í—ˆìš©ì˜¤ì°¨ë¥¼ ë‚˜ì—´í•˜ì„¸ìš”.'
    }
  ]
};

const elements = {
  pageTitle: document.getElementById('pageTitle'),
  detectForm: document.getElementById('detectForm'),
  browseBtn: document.getElementById('browseBtn'),
  cameraBtn: document.getElementById('cameraBtn'),
  modelSelect: document.getElementById('modelSelect'),
  modelQuickSelect: document.getElementById('modelQuickSelect'),
  photoInput: document.getElementById('photoInput'),
  cameraInput: document.getElementById('cameraInput'),
  dropzone: document.querySelector('[data-dropzone]'),
  fileHint: document.getElementById('fileHint'),
  previewWrap: document.getElementById('previewWrap'),
  previewImage: document.getElementById('previewImage'),
  promptChips: document.getElementById('promptChips'),
  promptInput: document.getElementById('promptInput'),
  statusBanner: document.getElementById('statusBanner'),
  analyzeBtn: document.getElementById('analyzeBtn'),
  descriptionOutput: document.getElementById('descriptionOutput'),
  objectsGrid: document.getElementById('objectsGrid'),
  rawOutput: document.getElementById('rawOutput'),
  modelTag: document.getElementById('modelTag'),
  latencyTag: document.getElementById('latencyTag'),
  heroEyebrow: document.getElementById('heroEyebrow'),
  heroTitle: document.getElementById('heroTitle'),
  heroLede: document.getElementById('heroLede'),
  langLabel: document.getElementById('langLabel'),
  uploadHeading: document.getElementById('uploadHeading'),
  uploadBody: document.getElementById('uploadBody'),
  dropTitle: document.getElementById('dropTitle'),
  dropAlt: document.getElementById('dropAlt'),
  promptHeading: document.getElementById('promptHeading'),
  promptBody: document.getElementById('promptBody'),
  promptLabel: document.getElementById('promptLabel'),
  summaryHeading: document.getElementById('summaryHeading'),
  objectsHeading: document.getElementById('objectsHeading'),
  objectsSubheading: document.getElementById('objectsSubheading'),
  rawHeading: document.getElementById('rawHeading'),
  rawSubheading: document.getElementById('rawSubheading'),
  chatHeading: document.getElementById('chatHeading'),
  chatSubheading: document.getElementById('chatSubheading'),
  chatLog: document.getElementById('chatLog'),
  chatForm: document.getElementById('chatForm'),
  chatInput: document.getElementById('chatInput'),
  chatSendBtn: document.getElementById('chatSendBtn'),
  chatMicBtn: document.getElementById('chatMicBtn'),
  chatPresets: document.getElementById('chatPresets'),
  languageSelect: document.getElementById('languageSelect')
};

const state = {
  language: DEFAULT_LANGUAGE,
  models: [],
  selectedModel: null,
  promptSamples: [],
  selectedPromptId: null,
  selectedFile: null,
  isAnalyzing: false,
  hasAnalysis: false,
  hasRaw: false,
  hasObjects: false,
  statusKey: 'statusWaiting',
  statusState: '',
  statusOverride: null,
  analysisContext: null,
  chatHistory: [],
  isChatting: false,
  speechRecognition: null,
  isDictating: false,
  dictationBase: ''
};

let promptInputDirty = false;

const updateModelSelectors = () => {
  const selects = [elements.modelSelect, elements.modelQuickSelect].filter(Boolean);
  selects.forEach((select) => {
    select.innerHTML = '';
    if (!state.models.length) {
      select.disabled = true;
      const option = document.createElement('option');
      option.value = '';
      option.textContent = 'â€”';
      select.appendChild(option);
      return;
    }
    state.models.forEach((model) => {
      const option = document.createElement('option');
      option.value = model;
      option.textContent = model;
      option.selected = model === state.selectedModel;
      select.appendChild(option);
    });
    select.disabled = false;
  });
};

const setSelectedModel = (model) => {
  if (model && state.models.includes(model)) {
    state.selectedModel = model;
  } else if (!state.selectedModel && state.models.length) {
    state.selectedModel = state.models[0];
  } else if (!state.models.length) {
    state.selectedModel = null;
  }
  updateModelSelectors();
};

const fetchModelOptions = async () => {
  try {
    const response = await fetch('/test/detects/api/models');
    if (!response.ok) throw new Error('model_list_failed');
    const data = await response.json();
    const list = Array.isArray(data.models) ? data.models.filter(Boolean) : [];
    if (list.length) {
      state.models = list;
      let preferred = null;
      if (list.includes(PREFERRED_VISION_MODEL)) {
        preferred = PREFERRED_VISION_MODEL;
      } else if (typeof data.default === 'string' && list.includes(data.default)) {
        preferred = data.default;
      } else {
        preferred = list[0];
      }
      setSelectedModel(preferred);
    } else {
      state.models = [];
      setSelectedModel(null);
    }
  } catch (error) {
    console.error('Failed to load model list', error);
    if (!state.models.length) {
      state.selectedModel = null;
      updateModelSelectors();
    }
  }
};

async function handleChatSubmit(event) {
  event.preventDefault();
  if (state.isChatting) return;
  if (!state.analysisContext) {
    setStatus('statusNeedAnalysis', 'error');
    return;
  }
  const question = elements.chatInput?.value?.trim();
  if (!question) return;

  appendChatMessage('user', question);
  pushChatHistory({ role: 'user', content: question });
  if (elements.chatInput) elements.chatInput.value = '';

  stopSpeaking();
  const thinkingText = t('chatThinking') || 'Thinkingâ€¦';
  const pendingMessage = appendChatMessage('assistant', thinkingText, { pending: true });
  setChatBusy(true);

  try {
    const response = await fetch('/test/detects/api/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        question,
        description: state.analysisContext?.description || '',
        objects: state.analysisContext?.objects || [],
        language: state.language,
        history: state.chatHistory
      })
    });
    if (!response.ok) {
      const detail = await response.text();
      throw new Error(detail || 'chat_failed');
    }
    const data = await response.json();
    const reply = (data?.reply || '').trim();
    const replyLanguage = (data?.language || state.language || '').trim() || state.language;
    if (pendingMessage) {
      pendingMessage.classList.remove('pending');
      const body = pendingMessage.querySelector('.chat-body');
      if (body) body.textContent = reply || t('chatError');
      applySpeakerState(pendingMessage, { text: reply, language: replyLanguage, enable: true });
    }
    if (reply) {
      pushChatHistory({ role: 'assistant', content: reply });
    }
  } catch (error) {
    console.error('Chat failed', error);
    if (pendingMessage) {
      pendingMessage.classList.remove('pending');
      const body = pendingMessage.querySelector('.chat-body');
      if (body) body.textContent = t('chatError');
      applySpeakerState(pendingMessage, { text: '', language: state.language, enable: false });
    }
  } finally {
    setChatBusy(false);
  }
}

const initModelSelectors = () => {
  [elements.modelSelect, elements.modelQuickSelect].forEach((select) => {
    if (!select) return;
    select.addEventListener('change', (event) => {
      const value = event.target.value;
      if (value) setSelectedModel(value);
    });
  });
  fetchModelOptions();
};

const updateSpeechRecognitionLocale = () => {
  if (!state.speechRecognition) return;
  const locale = resolveSpeechLocale(state.language);
  state.speechRecognition.lang = locale;
};

const getSpeechRecognitionCtor = () => {
  if (!SUPPORTS_SPEECH_RECOGNITION) return null;
  return window.SpeechRecognition || window.webkitSpeechRecognition || null;
};

const updateDictationState = (recording) => {
  state.isDictating = Boolean(recording);
  if (elements.chatMicBtn) {
    elements.chatMicBtn.classList.toggle('recording', state.isDictating);
    elements.chatMicBtn.setAttribute('aria-pressed', state.isDictating ? 'true' : 'false');
  }
  updateChatAvailability();
};

const applyDictationTranscript = (transcript, isFinal = false) => {
  if (!elements.chatInput || !transcript) return;
  const text = transcript.trim();
  if (!text) return;
  if (isFinal) {
    state.dictationBase = text;
  }
  elements.chatInput.value = text;
  elements.chatInput.focus();
};

const attachRecognitionHandlers = (recognition) => {
  if (!recognition) return;
  recognition.onstart = () => updateDictationState(true);
  recognition.onend = () => updateDictationState(false);
  recognition.onerror = () => updateDictationState(false);
  recognition.onresult = (event) => {
    if (!event.results?.length) return;
    let combined = '';
    let finalResult = false;
    for (let i = event.resultIndex; i < event.results.length; i += 1) {
      const result = event.results[i];
      if (!result?.[0]) continue;
      combined += result[0].transcript || '';
      if (result.isFinal) {
        finalResult = true;
      }
    }
    if (combined) {
      applyDictationTranscript(combined, finalResult);
    }
  };
};

const ensureSpeechRecognition = () => {
  if (state.speechRecognition) return state.speechRecognition;
  const Ctor = getSpeechRecognitionCtor();
  if (!Ctor) {
    state.speechRecognition = null;
    return null;
  }
  try {
    const recognition = new Ctor();
    recognition.continuous = false;
    recognition.interimResults = true;
    recognition.maxAlternatives = 1;
    state.speechRecognition = recognition;
    updateSpeechRecognitionLocale();
    attachRecognitionHandlers(recognition);
    updateChatAvailability();
    return recognition;
  } catch (error) {
    console.warn('Failed to init speech recognition', error);
    state.speechRecognition = null;
    updateChatAvailability();
    return null;
  }
};

const stopDictation = () => {
  if (!state.speechRecognition) return;
  try {
    state.speechRecognition.stop();
  } catch {
    /* ignore */
  }
  updateDictationState(false);
};

const startDictation = () => {
  const recognition = ensureSpeechRecognition();
  if (!recognition) return;
  try {
    recognition.stop();
  } catch {
    /* ignore */
  }
  try {
    recognition.start();
  } catch (error) {
    console.warn('Speech recognition start failed', error);
  }
};

const handleMicButtonClick = (event) => {
  event.preventDefault();
  event.stopPropagation();
  if (!state.speechRecognition) {
    ensureSpeechRecognition();
    return;
  }
  if (state.isDictating) {
    stopDictation();
  } else {
    startDictation();
  }
};

const initSpeechInput = () => {
  if (!elements.chatMicBtn) return;
  const ctor = getSpeechRecognitionCtor();
  if (!ctor) {
    elements.chatMicBtn.hidden = true;
    return;
  }
  elements.chatMicBtn.hidden = false;
  elements.chatMicBtn.addEventListener('click', handleMicButtonClick);
  ensureSpeechRecognition();
};

const updateChatAvailability = () => {
  const canChat = Boolean(state.analysisContext) && !state.isChatting;
  if (elements.chatInput) elements.chatInput.disabled = !canChat;
  if (elements.chatSendBtn) elements.chatSendBtn.disabled = !canChat;
  if (elements.chatMicBtn) {
    const hasRecognition = Boolean(state.speechRecognition);
    const shouldDisable = (!hasRecognition || !canChat) && !state.isDictating;
    elements.chatMicBtn.disabled = shouldDisable;
    elements.chatMicBtn.hidden = !hasRecognition;
    elements.chatMicBtn.classList.toggle('recording', state.isDictating);
  }
};

const pushChatHistory = (entry) => {
  if (!entry || typeof entry !== 'object') return;
  const role = entry.role;
  const content = typeof entry.content === 'string' ? entry.content.trim() : '';
  if (!role || !content) return;
  state.chatHistory.push({ role, content });
  if (state.chatHistory.length > 8) {
    state.chatHistory = state.chatHistory.slice(-8);
  }
};

const getChatLabels = () => ({
  user: t('chatUserLabel') || 'You',
  assistant: t('chatAssistantLabel') || 'Vision analyst'
});

const showChatPlaceholder = () => {
  if (!elements.chatLog) return;
  elements.chatLog.innerHTML = '';
  const placeholder = document.createElement('p');
  placeholder.className = 'chat-empty';
  placeholder.textContent = t('chatEmpty');
  elements.chatLog.appendChild(placeholder);
};

const clearChatPlaceholder = () => {
  if (!elements.chatLog) return;
  elements.chatLog.querySelectorAll('.chat-empty').forEach((node) => node.remove());
};

const resetChatConversation = () => {
  stopSpeaking();
  state.chatHistory = [];
  state.isChatting = false;
  if (elements.chatInput) elements.chatInput.value = '';
  updateChatAvailability();
  showChatPlaceholder();
};

const clearChatContext = () => {
  state.analysisContext = null;
  resetChatConversation();
  updateChatAvailability();
};

const setChatBusy = (busy) => {
  state.isChatting = busy;
  updateChatAvailability();
};

const supportsSpeechSynthesis = typeof window !== 'undefined' && 'speechSynthesis' in window;
let activeUtterance = null;

const setSpeakerIcon = (button, isPlaying) => {
  if (!button) return;
  const icon = button.querySelector('.icon');
  const playing = Boolean(isPlaying);
  const label = playing ? t('chatSpeakerStop') || 'Stop audio' : t('chatSpeakerButton') || 'Play audio response';
  if (icon) {
    icon.textContent = playing ? 'â¹' : 'ðŸ”Š';
  } else {
    button.textContent = playing ? 'â¹' : 'ðŸ”Š';
  }
  button.setAttribute('aria-label', label);
  button.title = label;
};

const stopSpeaking = () => {
  if (!supportsSpeechSynthesis) return;
  window.speechSynthesis.cancel();
  const activeButton = elements.chatLog?.querySelector('.chat-speaker-btn.is-speaking');
  if (activeButton) {
    activeButton.classList.remove('is-speaking');
    setSpeakerIcon(activeButton, false);
  }
  activeUtterance = null;
};

const speakText = (text, locale, buttonEl) => {
  if (!supportsSpeechSynthesis || !text) return;
  stopSpeaking();
  activeUtterance = new SpeechSynthesisUtterance(text);
  activeUtterance.lang = locale || resolveSpeechLocale(state.language);
  activeUtterance.rate = 1;
  if (buttonEl) {
    buttonEl.classList.add('is-speaking');
    setSpeakerIcon(buttonEl, true);
  }
  activeUtterance.onend = activeUtterance.onerror = () => {
    if (buttonEl) {
      buttonEl.classList.remove('is-speaking');
      setSpeakerIcon(buttonEl, false);
    }
    activeUtterance = null;
  };
  window.speechSynthesis.speak(activeUtterance);
};

elements.chatLog?.addEventListener('click', (event) => {
  const speakerBtn = event.target.closest('.chat-speaker-btn');
  if (!speakerBtn || speakerBtn.hidden) return;
  const text = speakerBtn.dataset.speakText;
  if (!text) return;
  const lang = speakerBtn.dataset.speakLang || resolveSpeechLocale(state.language);
  speakText(text, lang, speakerBtn);
});

const applySpeakerState = (container, { text, language, enable }) => {
  if (!container) return;
  const button = container.querySelector('.chat-speaker-btn');
  if (!button) return;
  const speechText = (text || '').trim();
  const canUseSpeech =
    enable && supportsSpeechSynthesis && speechText && speechText.length <= MAX_SPEECH_CHARACTERS;
  if (canUseSpeech) {
    button.hidden = false;
    button.dataset.speakText = speechText;
    button.dataset.speakLang = resolveSpeechLocale(language);
    setSpeakerIcon(button, false);
  } else {
    button.hidden = true;
    button.removeAttribute('data-speak-text');
    button.removeAttribute('data-speak-lang');
    button.classList.remove('is-speaking');
    setSpeakerIcon(button, false);
  }
};

const appendChatMessage = (role, content, { pending = false, canSpeak = false, language } = {}) => {
  if (!elements.chatLog) return null;
  clearChatPlaceholder();
  const message = document.createElement('div');
  message.className = `chat-message ${role}`;
  if (pending) message.classList.add('pending');
  const labelRow = document.createElement('div');
  labelRow.className = 'chat-label-row';
  const label = document.createElement('span');
  label.className = 'chat-label';
  const labels = getChatLabels();
  label.textContent = role === 'user' ? labels.user : labels.assistant;
  labelRow.appendChild(label);
  if (role === 'assistant') {
    const controls = document.createElement('div');
    controls.className = 'chat-controls';
    const speakBtn = document.createElement('button');
    speakBtn.type = 'button';
    speakBtn.className = 'chat-speaker-btn';
    speakBtn.innerHTML = '<span class="icon">ðŸ”Š</span>';
    speakBtn.title = t('chatSpeakerButton') || 'Play audio';
    speakBtn.hidden = true;
    controls.appendChild(speakBtn);
    labelRow.appendChild(controls);
  }
  const body = document.createElement('p');
  body.className = 'chat-body';
  body.textContent = content;
  message.append(labelRow, body);
  elements.chatLog.appendChild(message);
  elements.chatLog.scrollTop = elements.chatLog.scrollHeight;
  if (!pending && role === 'assistant') {
    applySpeakerState(message, { text: content, language, enable: canSpeak });
  }
  return message;
};

const refreshChatLocale = () => {
  if (!elements.chatLog) return;
  if (!state.chatHistory.length && !state.isChatting) {
    showChatPlaceholder();
    return;
  }
  const labels = getChatLabels();
  elements.chatLog.querySelectorAll('.chat-message.user .chat-label').forEach((label) => {
    label.textContent = labels.user;
  });
  elements.chatLog.querySelectorAll('.chat-message.assistant .chat-label').forEach((label) => {
    label.textContent = labels.assistant;
  });
  elements.chatLog.querySelectorAll('.chat-speaker-btn').forEach((button) => {
    button.title = t('chatSpeakerButton') || 'Play audio response';
  });
};

const getStrings = (lang = state.language) => ({
  ...UI_COPY.default,
  ...(UI_COPY[lang] || {})
});

const t = (key, fallback = '') => {
  if (!key) return fallback;
  const strings = getStrings();
  return strings[key] ?? fallback ?? key;
};

const setStatus = (key, stateClass = '', overrideText) => {
  state.statusKey = key || 'statusWaiting';
  state.statusState = stateClass || '';
  state.statusOverride = overrideText ?? null;

  const text = overrideText || t(state.statusKey);
  if (!elements.statusBanner) return;
  elements.statusBanner.textContent = text;
  elements.statusBanner.classList.remove('ok', 'error');
  if (state.statusState === 'ok') elements.statusBanner.classList.add('ok');
  if (state.statusState === 'error') elements.statusBanner.classList.add('error');
};

const refreshStatus = () => setStatus(state.statusKey, state.statusState, state.statusOverride);

const renderChatPresets = () => {
  if (!elements.chatPresets) return;
  elements.chatPresets.innerHTML = '';
  const presets = CHAT_PRESET_TEMPLATES.map((preset) => ({
    id: preset.id,
    label: t(preset.labelKey, preset.fallbackLabel),
    text: t(preset.textKey, preset.fallbackText)
  }));
  presets.forEach((preset) => {
    const button = document.createElement('button');
    button.type = 'button';
    button.className = 'preset';
    button.innerHTML = `<strong>${preset.label}</strong><span>${preset.text}</span>`;
    button.addEventListener('click', () => {
      if (!elements.chatInput) return;
      elements.chatInput.value = preset.text;
      elements.chatInput.focus();
    });
    elements.chatPresets.appendChild(button);
  });
};

const setLoading = (loading) => {
  state.isAnalyzing = loading;
  if (!elements.analyzeBtn) return;
  elements.analyzeBtn.disabled = loading;
  elements.analyzeBtn.textContent = loading ? t('analyzeButtonBusy') : t('analyzeButtonIdle');
};

const resetOutputs = () => {
  state.hasAnalysis = false;
  state.hasRaw = false;
  state.hasObjects = false;
  clearChatContext();
  if (elements.descriptionOutput) elements.descriptionOutput.textContent = t('summaryEmpty');
  if (elements.rawOutput) elements.rawOutput.textContent = t('rawPlaceholder');
  if (elements.objectsGrid) {
    elements.objectsGrid.innerHTML = '';
    const empty = document.createElement('p');
    empty.className = 'muted';
    empty.textContent = t('objectsEmpty');
    elements.objectsGrid.appendChild(empty);
  }
  if (elements.modelTag) elements.modelTag.textContent = 'â€”';
  if (elements.latencyTag) elements.latencyTag.textContent = 'â€”';
};

const updateFileState = (file) => {
  state.selectedFile = file || null;
  if (!file) {
    if (elements.fileHint) elements.fileHint.textContent = t('fileHintEmpty');
    if (elements.previewWrap) elements.previewWrap.classList.add('hidden');
    if (elements.previewImage) elements.previewImage.src = '';
    resetOutputs();
    return;
  }
  clearChatContext();

  if (elements.fileHint) {
    const sizeMb = (file.size / 1024 / 1024).toFixed(2);
    elements.fileHint.textContent = `${file.name} Â· ${sizeMb} MB`;
  }
  const reader = new FileReader();
  reader.onload = (event) => {
    if (elements.previewImage) elements.previewImage.src = event.target.result;
    if (elements.previewWrap) elements.previewWrap.classList.remove('hidden');
  };
  reader.readAsDataURL(file);
};

const renderObjects = (objects = []) => {
  if (!elements.objectsGrid) return;
  elements.objectsGrid.innerHTML = '';
  if (!objects.length) {
    const empty = document.createElement('p');
    empty.className = 'muted';
    empty.textContent = t('objectsEmpty');
    elements.objectsGrid.appendChild(empty);
    state.hasObjects = false;
    return;
  }
  state.hasObjects = true;
  objects
    .slice()
    .sort((a, b) => (b.confidence || 0) - (a.confidence || 0))
    .forEach((obj) => {
      const pill = document.createElement('div');
      pill.className = 'object-pill';
      const label = document.createElement('h3');
      label.textContent = obj.label || 'Unknown object';
      const meta = document.createElement('p');
      const conf = typeof obj.confidence === 'number' ? `${(obj.confidence * 100).toFixed(1)}%` : 'â€”';
      const detail = obj.detail ? ` â€¢ ${obj.detail}` : '';
      meta.textContent = `Confidence ${conf}${detail}`;
      pill.append(label, meta);
      elements.objectsGrid.appendChild(pill);
    });
};

const buildPromptSamples = () =>
  DETECTION_PROMPT_TEMPLATES.map((template) => ({
    id: template.id,
    label: t(template.labelKey, template.fallbackLabel),
    text: t(template.textKey, template.fallbackText)
  }));

const renderPromptChips = () => {
  if (!elements.promptChips) return;
  elements.promptChips.innerHTML = '';
  state.promptSamples = buildPromptSamples();
  state.promptSamples.forEach((sample) => {
    const chip = document.createElement('button');
    chip.type = 'button';
    chip.className = 'chip';
    chip.dataset.promptId = sample.id;
    chip.innerHTML = `<strong>${sample.label}</strong><span>${sample.text}</span>`;
    chip.addEventListener('click', () => selectPrompt(sample.id, true));
    elements.promptChips.appendChild(chip);
  });
  const fallbackId = state.promptSamples[0]?.id;
  if (fallbackId) {
    selectPrompt(fallbackId, false);
  }
};

const selectPrompt = (promptId, userInitiated = false) => {
  const sample = state.promptSamples.find((entry) => entry.id === promptId);
  if (!sample) return;
  state.selectedPromptId = sample.id;
  if (!promptInputDirty || userInitiated) {
    if (elements.promptInput) elements.promptInput.value = sample.text;
    promptInputDirty = false;
  }
  if (elements.promptChips) {
    elements.promptChips.querySelectorAll('.chip').forEach((chip) => {
      chip.classList.toggle('active', chip.dataset.promptId === sample.id);
    });
  }
};

const handleFiles = (files) => {
  if (!files?.length) {
    updateFileState(null);
    setStatus('statusWaiting');
    return;
  }
  const file = files[0];
  if (!file.type.startsWith('image/')) {
    setStatus('statusInvalidFile', 'error');
    return;
  }
  if (file.size > 10 * 1024 * 1024) {
    setStatus('statusFileTooLarge', 'error');
    return;
  }
  updateFileState(file);
  setStatus('statusPhotoReady');
};

const bindDropzone = () => {
  if (!elements.dropzone) return;
  const prevent = (event) => {
    event.preventDefault();
    event.stopPropagation();
  };
  ['dragenter', 'dragover', 'dragleave', 'drop'].forEach((eventName) => {
    elements.dropzone.addEventListener(eventName, prevent);
  });
  elements.dropzone.addEventListener('dragenter', () => elements.dropzone.classList.add('drag-over'));
  elements.dropzone.addEventListener('dragover', () => elements.dropzone.classList.add('drag-over'));
  elements.dropzone.addEventListener('dragleave', () => elements.dropzone.classList.remove('drag-over'));
  elements.dropzone.addEventListener('drop', (event) => {
    elements.dropzone.classList.remove('drag-over');
    handleFiles(event.dataTransfer.files);
  });
  elements.dropzone.addEventListener('click', (event) => {
    const interactive = event.target.closest('button, input, label, select, textarea, a');
    if (interactive) {
      return;
    }
    elements.photoInput?.click();
  });
};

const handleSubmit = async (event) => {
  event.preventDefault();
  if (!state.selectedFile) {
    setStatus('statusNeedPhoto', 'error');
    return;
  }
  const prompt = elements.promptInput?.value?.trim();
  if (!prompt) {
    setStatus('statusNeedPrompt', 'error');
    return;
  }

  const formData = new FormData();
  formData.append('photo', state.selectedFile, state.selectedFile.name);
  formData.append('prompt', prompt);
  if (state.selectedModel) {
    formData.append('model', state.selectedModel);
  }

  setStatus('statusAnalyzing');
  setLoading(true);

  try {
    const response = await fetch('/test/detects/api/analyze', {
      method: 'POST',
      body: formData
    });
    if (!response.ok) {
      const detail = await response.text();
      throw new Error(detail || 'Vision analyze failed');
    }
    const result = await response.json();
    state.hasAnalysis = true;
    state.hasRaw = true;
    if (elements.descriptionOutput) {
      elements.descriptionOutput.textContent = result.description || t('summaryEmpty');
    }
    renderObjects(result.objects || []);
    if (elements.rawOutput) {
      elements.rawOutput.textContent = JSON.stringify(result.raw ?? result, null, 2);
    }
    if (elements.modelTag) {
      elements.modelTag.textContent = result.model || 'â€”';
    }
    if (elements.latencyTag) {
      elements.latencyTag.textContent = result.latencyMs ? `${result.latencyMs} ms` : 'â€”';
    }
    state.analysisContext = {
      description: result.description || '',
      objects: Array.isArray(result.objects) ? result.objects : []
    };
    resetChatConversation();
    setStatus('statusAnalyzeComplete', 'ok');
  } catch (error) {
    console.error('Analyze failed', error);
    const detail = error?.message && error.message !== 'Vision analyze failed' ? error.message : null;
    setStatus('statusAnalyzeFailed', 'error', detail || undefined);
  } finally {
    setLoading(false);
  }
};

const applyLocaleToUI = () => {
  const textPairs = [
    [elements.pageTitle, 'heroTitle'],
    [elements.heroEyebrow, 'heroEyebrow'],
    [elements.heroTitle, 'heroTitle'],
    [elements.heroLede, 'heroLede'],
    [elements.langLabel, 'langLabel'],
    [elements.uploadHeading, 'uploadHeading'],
    [elements.uploadBody, 'uploadBody'],
    [elements.dropTitle, 'dropTitle'],
    [elements.promptHeading, 'promptHeading'],
    [elements.promptBody, 'promptBody'],
    [elements.promptLabel, 'promptLabel'],
    [elements.modelLabel, 'modelLabel'],
    [elements.modelTagLabel, 'modelTagLabel'],
    [elements.latencyLabel, 'latencyLabel'],
    [elements.summaryHeading, 'summaryHeading'],
    [elements.objectsHeading, 'objectsHeading'],
    [elements.objectsSubheading, 'objectsSubheading'],
    [elements.rawHeading, 'rawHeading'],
    [elements.rawSubheading, 'rawSubheading'],
    [elements.chatHeading, 'chatHeading'],
    [elements.chatSubheading, 'chatSubheading']
  ];
  textPairs.forEach(([el, key]) => {
    if (el) el.textContent = t(key);
  });
  if (elements.dropAlt) elements.dropAlt.textContent = t('dropAlt');
  if (elements.browseBtn) elements.browseBtn.textContent = t('browseButton');
  if (elements.cameraBtn) elements.cameraBtn.textContent = t('cameraButton');
  if (elements.promptInput) elements.promptInput.placeholder = t('promptPlaceholder');
  if (elements.chatInput) elements.chatInput.placeholder = t('chatPlaceholder');
  if (elements.chatSendBtn) elements.chatSendBtn.textContent = t('chatSendButton');
  if (!state.selectedFile && elements.fileHint) elements.fileHint.textContent = t('fileHintEmpty');
  if (!state.hasAnalysis && elements.descriptionOutput) elements.descriptionOutput.textContent = t('summaryEmpty');
  if (!state.hasRaw && elements.rawOutput) elements.rawOutput.textContent = t('rawPlaceholder');
  if (!state.hasObjects) renderObjects([]);
  setLoading(state.isAnalyzing);
  refreshChatLocale();
};

const populateLanguageSelect = () => {
  if (!elements.languageSelect) return;
  elements.languageSelect.innerHTML = '';
  LANGUAGE_OPTIONS.forEach((opt) => {
    const option = document.createElement('option');
    option.value = opt.value;
    option.textContent = `${opt.label} â€” ${opt.description}`;
    if (opt.value === state.language) option.selected = true;
    elements.languageSelect.appendChild(option);
  });
};

const setLanguage = (lang) => {
  const exists = LANGUAGE_OPTIONS.some((entry) => entry.value === lang);
  state.language = exists ? lang : DEFAULT_LANGUAGE;
  document.documentElement.lang = state.language;
  updateSpeechRecognitionLocale();
  try {
    localStorage.setItem('detectsLanguage', state.language);
  } catch {
    /* ignore */
  }
  promptInputDirty = false;
  state.selectedPromptId = null;
  populateLanguageSelect();
  renderPromptChips();
  renderChatPresets();
  applyLocaleToUI();
  refreshStatus();
};

const initLanguageSwitcher = () => {
  if (!elements.languageSelect) return;
  elements.languageSelect.addEventListener('change', (event) => {
    setLanguage(event.target.value);
  });
};

const init = () => {
  bindDropzone();
  initModelSelectors();
  updateChatAvailability();
  elements.browseBtn?.addEventListener('click', (event) => {
    event.preventDefault();
    event.stopPropagation();
    elements.photoInput?.click();
  });
  elements.photoInput?.addEventListener('change', (event) => handleFiles(event.target.files));
  elements.cameraBtn?.addEventListener('click', (event) => {
    event.preventDefault();
    event.stopPropagation();
    elements.cameraInput?.click();
  });
  elements.cameraInput?.addEventListener('change', (event) => handleFiles(event.target.files));
  elements.detectForm?.addEventListener('submit', handleSubmit);
  elements.chatForm?.addEventListener('submit', handleChatSubmit);
  initSpeechInput();
  elements.promptInput?.addEventListener('input', () => {
    promptInputDirty = true;
  });

  const stored = (() => {
    try {
      return localStorage.getItem('detectsLanguage');
    } catch {
      return null;
    }
  })();
  setLanguage(stored || DEFAULT_LANGUAGE);
  setStatus('statusWaiting');
  initLanguageSwitcher();
  showChatPlaceholder();
};

init();
